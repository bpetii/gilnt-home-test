
To solve the problem of finding the maximum wave height since 1979, I would follow these steps:
1. Get the netcdf file which includes all the data from 1979.
2. If we have a netcdf file with even more data dating back before 1979, I would filter data to include measurements since 1979 : 
`data_since_1979 = data_at_specific_location.sel(time=slice('1979-01-01'))`
3. I also would use my current solution to compute the maximium wave height from the filtered dataset: `data_since_1979.hmax.max().values.item()`
4. Considering the longer time span and potential data quality issue with historical records, I would perform quality check or create a guard to validate the computed maximum value.


Points of concerns:
- Mentioned before - data quality
- Computational resources - analyzing such a huge dataset (over 5-10 million) spanning several decades require significant resources.

If you assume that the data quality is ok, and assume that the data comes in as many netcdf files, one for each day. How would you practically go about and solve the problem? You mention the data is huge, how huge? 

1. I'd setup system to ingest daily netCDF file into the application. It's either a scheduled task or a real-time monitoring for new files.
2. Storing netCDF file efficiently (InfluxDB), maybe I would store the max wave height per location to be a reference point for the daily netcdf file.
3. Given that each day's data consists of 4.5 million data points, developing an algorithm the process the netCDF file would be efficient and necessary.
However python is really powerful processing huge data using xarray, thus consistently storing the highest wave in a database and updating it daily, provided the new netCDF file contains a larger value, is feasible and manageable.
4. We only want to process new or updated files since the last run, so I would implement a mechanism to track the processed files and only process the new ones.

This approach ensures that only the highest wave height for each day is stored in the database, simplifying the processing algorithm. It leverages the efficient data handling capabilities of xarray for working with large netCDF files in Python.

I provided an example called second-question.py